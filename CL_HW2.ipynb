{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58895706",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322302e",
   "metadata": {},
   "source": [
    "# Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию\n",
    "\n",
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя.\n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6f7a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8eddf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   анализировать  бл  будет  бы  было  ватник  верблюдов  верим  во  вон  ...  \\\n",
      "0              1   1      1   2     1       1          1      1   1    1  ...   \n",
      "\n",
      "   том  ты  убедил  факт  хохлов  хохлы  хуже  числе  что  это  \n",
      "0    1   1       1     1       2      1     1      1    3    3  \n",
      "\n",
      "[1 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "text = '''Верблюдов-то за что? Дебилы, бл...\n",
    "\",\n",
    "\"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
    "\",\n",
    "\"Собаке - собачья смерть.\n",
    "\",\n",
    "\"Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
    "\",\n",
    "\"тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
    "'''\n",
    "regex = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "tokens = re.findall(regex, text.lower())\n",
    "vocab = sorted(set(tokens))\n",
    "counts = Counter(tokens)\n",
    "counts = [counts[key] for key in sorted(counts.keys())]\n",
    "print(pd.DataFrame([counts], columns = vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51e7f8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 12, 'Верблюдов-то'),\n",
       " Substring(13, 15, 'за'),\n",
       " Substring(16, 19, 'что'),\n",
       " Substring(19, 20, '?'),\n",
       " Substring(21, 27, 'Дебилы'),\n",
       " Substring(27, 28, ','),\n",
       " Substring(29, 31, 'бл'),\n",
       " Substring(31, 34, '...'),\n",
       " Substring(35, 36, '\"'),\n",
       " Substring(36, 37, ','),\n",
       " Substring(38, 39, '\"'),\n",
       " Substring(39, 44, 'Хохлы'),\n",
       " Substring(44, 45, ','),\n",
       " Substring(46, 49, 'это'),\n",
       " Substring(50, 58, 'отдушина'),\n",
       " Substring(59, 69, 'затюканого'),\n",
       " Substring(70, 80, 'россиянина'),\n",
       " Substring(80, 81, ','),\n",
       " Substring(82, 85, 'мол'),\n",
       " Substring(85, 86, ','),\n",
       " Substring(87, 90, 'вон'),\n",
       " Substring(90, 91, ','),\n",
       " Substring(92, 93, 'а'),\n",
       " Substring(94, 95, 'у'),\n",
       " Substring(96, 102, 'хохлов'),\n",
       " Substring(103, 106, 'еще'),\n",
       " Substring(107, 111, 'хуже'),\n",
       " Substring(111, 112, '.'),\n",
       " Substring(113, 117, 'Если'),\n",
       " Substring(118, 120, 'бы'),\n",
       " Substring(121, 127, 'хохлов'),\n",
       " Substring(128, 130, 'не'),\n",
       " Substring(131, 135, 'было'),\n",
       " Substring(135, 136, ','),\n",
       " Substring(137, 143, 'кисель'),\n",
       " Substring(144, 146, 'их'),\n",
       " Substring(147, 149, 'бы'),\n",
       " Substring(150, 158, 'придумал'),\n",
       " Substring(158, 159, '.'),\n",
       " Substring(160, 161, '\"'),\n",
       " Substring(161, 162, ','),\n",
       " Substring(163, 164, '\"'),\n",
       " Substring(164, 170, 'Собаке'),\n",
       " Substring(171, 172, '-'),\n",
       " Substring(173, 180, 'собачья'),\n",
       " Substring(181, 187, 'смерть'),\n",
       " Substring(187, 188, '.'),\n",
       " Substring(189, 190, '\"'),\n",
       " Substring(190, 191, ','),\n",
       " Substring(192, 193, '\"'),\n",
       " Substring(193, 201, 'Страницу'),\n",
       " Substring(202, 208, 'обнови'),\n",
       " Substring(208, 209, ','),\n",
       " Substring(210, 215, 'дебил'),\n",
       " Substring(215, 216, '.'),\n",
       " Substring(217, 220, 'Это'),\n",
       " Substring(221, 225, 'тоже'),\n",
       " Substring(226, 228, 'не'),\n",
       " Substring(229, 240, 'оскорбление'),\n",
       " Substring(240, 241, ','),\n",
       " Substring(242, 243, 'а'),\n",
       " Substring(244, 254, 'доказанный'),\n",
       " Substring(255, 259, 'факт'),\n",
       " Substring(260, 261, '-'),\n",
       " Substring(262, 270, 'не-дебил'),\n",
       " Substring(271, 274, 'про'),\n",
       " Substring(275, 279, 'себя'),\n",
       " Substring(280, 282, 'во'),\n",
       " Substring(283, 296, 'множественном'),\n",
       " Substring(297, 302, 'числе'),\n",
       " Substring(303, 309, 'писать'),\n",
       " Substring(310, 312, 'не'),\n",
       " Substring(313, 318, 'будет'),\n",
       " Substring(318, 319, '.'),\n",
       " Substring(320, 323, 'Или'),\n",
       " Substring(324, 326, 'мы'),\n",
       " Substring(327, 328, 'в'),\n",
       " Substring(329, 333, 'тебя'),\n",
       " Substring(334, 339, 'верим'),\n",
       " Substring(340, 341, '-'),\n",
       " Substring(342, 345, 'это'),\n",
       " Substring(346, 348, 'ты'),\n",
       " Substring(349, 350, 'и'),\n",
       " Substring(351, 355, 'твои'),\n",
       " Substring(356, 368, 'воображаемые'),\n",
       " Substring(369, 375, 'друзья'),\n",
       " Substring(375, 376, '?'),\n",
       " Substring(377, 378, '\"'),\n",
       " Substring(378, 379, ','),\n",
       " Substring(380, 381, '\"'),\n",
       " Substring(381, 385, 'тебя'),\n",
       " Substring(386, 388, 'не'),\n",
       " Substring(389, 395, 'убедил'),\n",
       " Substring(396, 408, '6-страничный'),\n",
       " Substring(409, 412, 'пдф'),\n",
       " Substring(413, 414, 'в'),\n",
       " Substring(415, 418, 'том'),\n",
       " Substring(418, 419, ','),\n",
       " Substring(420, 423, 'что'),\n",
       " Substring(424, 433, 'Скрипалей'),\n",
       " Substring(434, 442, 'отравила'),\n",
       " Substring(443, 449, 'Россия'),\n",
       " Substring(449, 450, '?'),\n",
       " Substring(451, 464, 'Анализировать'),\n",
       " Substring(465, 466, 'и'),\n",
       " Substring(467, 473, 'думать'),\n",
       " Substring(474, 483, 'пытаешься'),\n",
       " Substring(483, 484, '?'),\n",
       " Substring(485, 491, 'Ватник'),\n",
       " Substring(492, 495, 'что'),\n",
       " Substring(496, 498, 'ли'),\n",
       " Substring(498, 499, '?'),\n",
       " Substring(499, 500, ')')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "text = '''Верблюдов-то за что? Дебилы, бл...\n",
    "\",\n",
    "\"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
    "\",\n",
    "\"Собаке - собачья смерть.\n",
    "\",\n",
    "\"Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
    "\",\n",
    "\"тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
    "'''\n",
    "list(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "razdel.tokenize делит на токены и индексы, а векторайзер в sklearn подсчитывает частотность употребления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27926a",
   "metadata": {},
   "source": [
    "# Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42ef644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ты': 3, 'только': 2, 'не': 0, 'он': 1}\n",
      "[[0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 1 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = [\"я и ты\", \"ты и я\", \"я, я и только я\", \"только не я\", \"он\"]\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(text)\n",
    "print(vectorizer.vocabulary_)\n",
    "vector = vectorizer.transform(text)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6ca590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of: \n",
      "              я: 0.6989700043360189\n",
      "            Он.: 0.6989700043360189\n",
      "             не: 0.6989700043360189\n",
      "             я.: 0.2218487496163564\n",
      "             Ты: 0.6989700043360189\n",
      "             Я,: 0.6989700043360189\n",
      "              и: 0.2218487496163564\n",
      "         Только: 0.6989700043360189\n",
      "              Я: 0.6989700043360189\n",
      "         только: 0.6989700043360189\n",
      "            ты.: 0.6989700043360189\n"
     ]
    }
   ],
   "source": [
    "print(\"IDF of: \")\n",
    "n_docs = len(corpus)   \n",
    "idf = {}\n",
    "\n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k += 1\n",
    "            \n",
    "    idf[w] =  np.log10(n_docs / k)\n",
    "    \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2145a",
   "metadata": {},
   "source": [
    "# Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?\n",
    "\n",
    "Требования к классификаторам:\n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer\n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров\n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра\n",
    "г) f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71bc6314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35edcb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4120935",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be6eca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "635d5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'верблюдов': 6, 'то': 48, 'за': 18, 'что': 58, 'дебилы': 12, 'бл': 1, 'хохлы': 55, 'это': 59, 'отдушина': 30, 'затюканого': 19, 'россиянина': 38, 'мол': 25, 'вон': 9, 'хохлов': 54, 'еще': 17, 'хуже': 56, 'если': 16, 'бы': 3, 'не': 27, 'было': 4, 'кисель': 22, 'их': 21, 'придумал': 34, 'собаке': 42, 'собачья': 43, 'смерть': 41, 'страницу': 44, 'обнови': 28, 'дебил': 11, 'тоже': 49, 'оскорбление': 29, 'доказанный': 13, 'факт': 53, 'про': 35, 'себя': 39, 'во': 8, 'множественном': 24, 'числе': 57, 'писать': 33, 'будет': 2, 'или': 20, 'мы': 26, 'тебя': 47, 'верим': 7, 'ты': 51, 'твои': 46, 'воображаемые': 10, 'друзья': 14, 'убедил': 52, 'страничный': 45, 'пдф': 32, 'том': 50, 'скрипалей': 40, 'отравила': 31, 'россия': 37, 'анализировать': 0, 'думать': 15, 'пытаешься': 36, 'ватник': 5, 'ли': 23}\n",
      "(1, 60)\n",
      "[[1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 3 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "text = ['''Верблюдов-то за что? Дебилы, бл...\n",
    "\",\n",
    "\"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
    "\",\n",
    "\"Собаке - собачья смерть.\n",
    "\",\n",
    "\"Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
    "\",\n",
    "\"тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
    "''']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "\n",
    "vector = vectorizer.transform(text)\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9cb7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e4d73f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c0e87f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "702e6f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.76110315e-01, 2.38896852e-02],\n",
       "       [5.36537894e-01, 4.63462106e-01],\n",
       "       [3.35623640e-01, 6.64376360e-01],\n",
       "       ...,\n",
       "       [4.07948447e-01, 5.92051553e-01],\n",
       "       [9.99856163e-01, 1.43836890e-04],\n",
       "       [9.43440184e-01, 5.65598162e-02]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be31bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      8605\n",
      "         1.0       0.96      0.94      0.95      4365\n",
      "\n",
      "    accuracy                           0.97     12970\n",
      "   macro avg       0.97      0.96      0.96     12970\n",
      "weighted avg       0.97      0.97      0.97     12970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X)\n",
    "\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87cd2da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'верблюдов': 6, 'то': 48, 'за': 18, 'что': 58, 'дебилы': 12, 'бл': 1, 'хохлы': 55, 'это': 59, 'отдушина': 30, 'затюканого': 19, 'россиянина': 38, 'мол': 25, 'вон': 9, 'хохлов': 54, 'еще': 17, 'хуже': 56, 'если': 16, 'бы': 3, 'не': 27, 'было': 4, 'кисель': 22, 'их': 21, 'придумал': 34, 'собаке': 42, 'собачья': 43, 'смерть': 41, 'страницу': 44, 'обнови': 28, 'дебил': 11, 'тоже': 49, 'оскорбление': 29, 'доказанный': 13, 'факт': 53, 'про': 35, 'себя': 39, 'во': 8, 'множественном': 24, 'числе': 57, 'писать': 33, 'будет': 2, 'или': 20, 'мы': 26, 'тебя': 47, 'верим': 7, 'ты': 51, 'твои': 46, 'воображаемые': 10, 'друзья': 14, 'убедил': 52, 'страничный': 45, 'пдф': 32, 'том': 50, 'скрипалей': 40, 'отравила': 31, 'россия': 37, 'анализировать': 0, 'думать': 15, 'пытаешься': 36, 'ватник': 5, 'ли': 23}\n",
      "(1, 60)\n",
      "[[0.09449112 0.09449112 0.09449112 0.18898224 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.18898224\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.47245559 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.09449112\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.18898224\n",
      "  0.09449112 0.09449112 0.09449112 0.09449112 0.09449112 0.09449112\n",
      "  0.18898224 0.09449112 0.09449112 0.09449112 0.28347335 0.28347335]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "text = ['''Верблюдов-то за что? Дебилы, бл...\n",
    "\",\n",
    "\"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
    "\",\n",
    "\"Собаке - собачья смерть.\n",
    "\",\n",
    "\"Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
    "\",\n",
    "\"тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
    "''']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "\n",
    "vector = vectorizer.transform(text)\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e331c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c06a3280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0106722e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a86648f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.76110315e-01, 2.38896852e-02],\n",
       "       [5.36537894e-01, 4.63462106e-01],\n",
       "       [3.35623640e-01, 6.64376360e-01],\n",
       "       ...,\n",
       "       [4.07948447e-01, 5.92051553e-01],\n",
       "       [9.99856163e-01, 1.43836890e-04],\n",
       "       [9.43440184e-01, 5.65598162e-02]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f99aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      8605\n",
      "         1.0       0.96      0.94      0.95      4365\n",
      "\n",
      "    accuracy                           0.97     12970\n",
      "   macro avg       0.97      0.96      0.96     12970\n",
      "weighted avg       0.97      0.97      0.97     12970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X)\n",
    "\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbebd829",
   "metadata": {},
   "source": [
    "# *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов.\n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01763f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
